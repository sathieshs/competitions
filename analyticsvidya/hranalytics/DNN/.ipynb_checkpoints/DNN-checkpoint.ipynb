{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "412fc585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eb4bb7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "626902a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pd.read_csv('../train_x.csv')\n",
    "Y=pd.read_csv('../train_y.csv')\n",
    "Y=Y['target']\n",
    "#X.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "Y=Y.to_numpy()\n",
    "X=X.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "37c8560d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test=train_test_split(X,Y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c46ae0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]\n",
    "\n",
    "def make_model(metrics=METRICS, output_bias=None):\n",
    "  model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Input(166),\n",
    "      tf.keras.layers.Dense(128, activation='relu'),\n",
    "      tf.keras.layers.Dropout(0.2),\n",
    "      tf.keras.layers.Dense(128, activation='relu'),\n",
    "      tf.keras.layers.Dense(128, activation='relu'),\n",
    "      tf.keras.layers.Dense(1,activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "  model.compile(\n",
    "      optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "      loss=keras.losses.BinaryCrossentropy(),\n",
    "      metrics=metrics)\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "93c3fa64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.88262367])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos=Y[Y==1].size\n",
    "neg=Y[Y==0].size\n",
    "initial_bias = np.log([pos/neg])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2154f67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_37 (Dense)            (None, 128)               21376     \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 54,529\n",
      "Trainable params: 54,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 2048\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_auc', \n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)\n",
    "\n",
    "model_bias = make_model(output_bias=initial_bias)\n",
    "model_bias.summary()\n",
    "hist_bias=model_bias.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=(x_test, y_test), \n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2fd227",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_zero_bias = make_model()\n",
    "model_zero_bias.summary()\n",
    "hist_zero_bias=model_zero_bias.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=(x_test, y_test), \n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d5850e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 2s 104ms/step - loss: 0.4711 - tp: 24.0000 - fp: 160.0000 - tn: 15774.0000 - fn: 2401.0000 - accuracy: 0.8605 - precision: 0.1304 - recall: 0.0099 - auc: 0.5272 - prc: 0.1403 - val_loss: 0.4593 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 2377.0000 - val_fn: 377.0000 - val_accuracy: 0.8631 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5155 - val_prc: 0.1591\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4194 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 13557.0000 - fn: 2048.0000 - accuracy: 0.8688 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5711 - prc: 0.1836 - val_loss: 0.4203 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 2377.0000 - val_fn: 377.0000 - val_accuracy: 0.8631 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5633 - val_prc: 0.1939\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3951 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 13557.0000 - fn: 2048.0000 - accuracy: 0.8688 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6224 - prc: 0.2155 - val_loss: 0.4052 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 2377.0000 - val_fn: 377.0000 - val_accuracy: 0.8631 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5968 - val_prc: 0.2074\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3823 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 13557.0000 - fn: 2048.0000 - accuracy: 0.8688 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6449 - prc: 0.2258 - val_loss: 0.3996 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 2376.0000 - val_fn: 377.0000 - val_accuracy: 0.8627 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6147 - val_prc: 0.2153\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3738 - tp: 1.0000 - fp: 2.0000 - tn: 13555.0000 - fn: 2047.0000 - accuracy: 0.8687 - precision: 0.3333 - recall: 4.8828e-04 - auc: 0.6623 - prc: 0.2296 - val_loss: 0.3945 - val_tp: 0.0000e+00 - val_fp: 3.0000 - val_tn: 2374.0000 - val_fn: 377.0000 - val_accuracy: 0.8620 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6273 - val_prc: 0.2227\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3702 - tp: 5.0000 - fp: 9.0000 - tn: 13548.0000 - fn: 2043.0000 - accuracy: 0.8685 - precision: 0.3571 - recall: 0.0024 - auc: 0.6712 - prc: 0.2345 - val_loss: 0.3925 - val_tp: 0.0000e+00 - val_fp: 2.0000 - val_tn: 2375.0000 - val_fn: 377.0000 - val_accuracy: 0.8624 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6299 - val_prc: 0.2201\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3652 - tp: 8.0000 - fp: 7.0000 - tn: 13550.0000 - fn: 2040.0000 - accuracy: 0.8688 - precision: 0.5333 - recall: 0.0039 - auc: 0.6857 - prc: 0.2449 - val_loss: 0.3910 - val_tp: 0.0000e+00 - val_fp: 2.0000 - val_tn: 2375.0000 - val_fn: 377.0000 - val_accuracy: 0.8624 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6322 - val_prc: 0.2189\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3617 - tp: 9.0000 - fp: 4.0000 - tn: 13553.0000 - fn: 2039.0000 - accuracy: 0.8691 - precision: 0.6923 - recall: 0.0044 - auc: 0.6925 - prc: 0.2592 - val_loss: 0.3910 - val_tp: 0.0000e+00 - val_fp: 3.0000 - val_tn: 2374.0000 - val_fn: 377.0000 - val_accuracy: 0.8620 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6327 - val_prc: 0.2198\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3604 - tp: 12.0000 - fp: 9.0000 - tn: 13548.0000 - fn: 2036.0000 - accuracy: 0.8690 - precision: 0.5714 - recall: 0.0059 - auc: 0.6947 - prc: 0.2619 - val_loss: 0.3911 - val_tp: 0.0000e+00 - val_fp: 3.0000 - val_tn: 2374.0000 - val_fn: 377.0000 - val_accuracy: 0.8620 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6338 - val_prc: 0.2234\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.3599 - tp: 16.0000 - fp: 12.0000 - tn: 13545.0000 - fn: 2032.0000 - accuracy: 0.8690 - precision: 0.5714 - recall: 0.0078 - auc: 0.6986 - prc: 0.2642 - val_loss: 0.3910 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 2374.0000 - val_fn: 376.0000 - val_accuracy: 0.8624 - val_precision: 0.2500 - val_recall: 0.0027 - val_auc: 0.6319 - val_prc: 0.2224\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.3563 - tp: 7.0000 - fp: 6.0000 - tn: 13551.0000 - fn: 2041.0000 - accuracy: 0.8688 - precision: 0.5385 - recall: 0.0034 - auc: 0.7082 - prc: 0.2772 - val_loss: 0.3921 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 2374.0000 - val_fn: 376.0000 - val_accuracy: 0.8624 - val_precision: 0.2500 - val_recall: 0.0027 - val_auc: 0.6319 - val_prc: 0.2228\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3548 - tp: 15.0000 - fp: 11.0000 - tn: 13546.0000 - fn: 2033.0000 - accuracy: 0.8690 - precision: 0.5769 - recall: 0.0073 - auc: 0.7120 - prc: 0.2814 - val_loss: 0.3935 - val_tp: 1.0000 - val_fp: 7.0000 - val_tn: 2370.0000 - val_fn: 376.0000 - val_accuracy: 0.8609 - val_precision: 0.1250 - val_recall: 0.0027 - val_auc: 0.6310 - val_prc: 0.2174\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3526 - tp: 17.0000 - fp: 7.0000 - tn: 13550.0000 - fn: 2031.0000 - accuracy: 0.8694 - precision: 0.7083 - recall: 0.0083 - auc: 0.7195 - prc: 0.2835 - val_loss: 0.3935 - val_tp: 1.0000 - val_fp: 5.0000 - val_tn: 2372.0000 - val_fn: 376.0000 - val_accuracy: 0.8617 - val_precision: 0.1667 - val_recall: 0.0027 - val_auc: 0.6319 - val_prc: 0.2166\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3520 - tp: 12.0000 - fp: 13.0000 - tn: 13544.0000 - fn: 2036.0000 - accuracy: 0.8687 - precision: 0.4800 - recall: 0.0059 - auc: 0.7220 - prc: 0.2831 - val_loss: 0.3945 - val_tp: 0.0000e+00 - val_fp: 9.0000 - val_tn: 2368.0000 - val_fn: 377.0000 - val_accuracy: 0.8598 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6332 - val_prc: 0.2155\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3505 - tp: 21.0000 - fp: 10.0000 - tn: 13547.0000 - fn: 2027.0000 - accuracy: 0.8695 - precision: 0.6774 - recall: 0.0103 - auc: 0.7244 - prc: 0.2953 - val_loss: 0.3933 - val_tp: 0.0000e+00 - val_fp: 7.0000 - val_tn: 2370.0000 - val_fn: 377.0000 - val_accuracy: 0.8606 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6343 - val_prc: 0.2150\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.3477 - tp: 17.0000 - fp: 8.0000 - tn: 13549.0000 - fn: 2031.0000 - accuracy: 0.8693 - precision: 0.6800 - recall: 0.0083 - auc: 0.7321 - prc: 0.3059 - val_loss: 0.3943 - val_tp: 0.0000e+00 - val_fp: 4.0000 - val_tn: 2373.0000 - val_fn: 377.0000 - val_accuracy: 0.8617 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6326 - val_prc: 0.2142\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.3463 - tp: 15.0000 - fp: 13.0000 - tn: 13544.0000 - fn: 2033.0000 - accuracy: 0.8689 - precision: 0.5357 - recall: 0.0073 - auc: 0.7358 - prc: 0.3096 - val_loss: 0.3958 - val_tp: 2.0000 - val_fp: 13.0000 - val_tn: 2364.0000 - val_fn: 375.0000 - val_accuracy: 0.8591 - val_precision: 0.1333 - val_recall: 0.0053 - val_auc: 0.6325 - val_prc: 0.2162\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3446 - tp: 14.0000 - fp: 11.0000 - tn: 13546.0000 - fn: 2034.0000 - accuracy: 0.8690 - precision: 0.5600 - recall: 0.0068 - auc: 0.7405 - prc: 0.3153 - val_loss: 0.3961 - val_tp: 5.0000 - val_fp: 15.0000 - val_tn: 2362.0000 - val_fn: 372.0000 - val_accuracy: 0.8595 - val_precision: 0.2500 - val_recall: 0.0133 - val_auc: 0.6346 - val_prc: 0.2166\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3438 - tp: 28.0000 - fp: 6.0000 - tn: 13551.0000 - fn: 2020.0000 - accuracy: 0.8702 - precision: 0.8235 - recall: 0.0137 - auc: 0.7425 - prc: 0.3277 - val_loss: 0.3969 - val_tp: 2.0000 - val_fp: 13.0000 - val_tn: 2364.0000 - val_fn: 375.0000 - val_accuracy: 0.8591 - val_precision: 0.1333 - val_recall: 0.0053 - val_auc: 0.6320 - val_prc: 0.2149\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3412 - tp: 42.0000 - fp: 19.0000 - tn: 13538.0000 - fn: 2006.0000 - accuracy: 0.8702 - precision: 0.6885 - recall: 0.0205 - auc: 0.7494 - prc: 0.3321 - val_loss: 0.3974 - val_tp: 1.0000 - val_fp: 9.0000 - val_tn: 2368.0000 - val_fn: 376.0000 - val_accuracy: 0.8602 - val_precision: 0.1000 - val_recall: 0.0027 - val_auc: 0.6342 - val_prc: 0.2182\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3411 - tp: 26.0000 - fp: 12.0000 - tn: 13545.0000 - fn: 2022.0000 - accuracy: 0.8697 - precision: 0.6842 - recall: 0.0127 - auc: 0.7491 - prc: 0.3316 - val_loss: 0.3986 - val_tp: 7.0000 - val_fp: 18.0000 - val_tn: 2359.0000 - val_fn: 370.0000 - val_accuracy: 0.8591 - val_precision: 0.2800 - val_recall: 0.0186 - val_auc: 0.6327 - val_prc: 0.2156\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3380 - tp: 39.0000 - fp: 19.0000 - tn: 13538.0000 - fn: 2009.0000 - accuracy: 0.8700 - precision: 0.6724 - recall: 0.0190 - auc: 0.7575 - prc: 0.3430 - val_loss: 0.3992 - val_tp: 5.0000 - val_fp: 13.0000 - val_tn: 2364.0000 - val_fn: 372.0000 - val_accuracy: 0.8602 - val_precision: 0.2778 - val_recall: 0.0133 - val_auc: 0.6328 - val_prc: 0.2164\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3367 - tp: 47.0000 - fp: 18.0000 - tn: 13539.0000 - fn: 2001.0000 - accuracy: 0.8706 - precision: 0.7231 - recall: 0.0229 - auc: 0.7603 - prc: 0.3445 - val_loss: 0.4011 - val_tp: 9.0000 - val_fp: 22.0000 - val_tn: 2355.0000 - val_fn: 368.0000 - val_accuracy: 0.8584 - val_precision: 0.2903 - val_recall: 0.0239 - val_auc: 0.6289 - val_prc: 0.2133\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3346 - tp: 49.0000 - fp: 28.0000 - tn: 13529.0000 - fn: 1999.0000 - accuracy: 0.8701 - precision: 0.6364 - recall: 0.0239 - auc: 0.7665 - prc: 0.3498 - val_loss: 0.4018 - val_tp: 8.0000 - val_fp: 22.0000 - val_tn: 2355.0000 - val_fn: 369.0000 - val_accuracy: 0.8580 - val_precision: 0.2667 - val_recall: 0.0212 - val_auc: 0.6297 - val_prc: 0.2156\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3345 - tp: 57.0000 - fp: 27.0000 - tn: 13530.0000 - fn: 1991.0000 - accuracy: 0.8707 - precision: 0.6786 - recall: 0.0278 - auc: 0.7650 - prc: 0.3511 - val_loss: 0.4039 - val_tp: 10.0000 - val_fp: 28.0000 - val_tn: 2349.0000 - val_fn: 367.0000 - val_accuracy: 0.8566 - val_precision: 0.2632 - val_recall: 0.0265 - val_auc: 0.6296 - val_prc: 0.2134\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3322 - tp: 77.0000 - fp: 45.0000 - tn: 13512.0000 - fn: 1971.0000 - accuracy: 0.8708 - precision: 0.6311 - recall: 0.0376 - auc: 0.7713 - prc: 0.3517 - val_loss: 0.4059 - val_tp: 11.0000 - val_fp: 34.0000 - val_tn: 2343.0000 - val_fn: 366.0000 - val_accuracy: 0.8548 - val_precision: 0.2444 - val_recall: 0.0292 - val_auc: 0.6278 - val_prc: 0.2090\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3309 - tp: 78.0000 - fp: 38.0000 - tn: 13519.0000 - fn: 1970.0000 - accuracy: 0.8713 - precision: 0.6724 - recall: 0.0381 - auc: 0.7745 - prc: 0.3645 - val_loss: 0.4046 - val_tp: 10.0000 - val_fp: 31.0000 - val_tn: 2346.0000 - val_fn: 367.0000 - val_accuracy: 0.8555 - val_precision: 0.2439 - val_recall: 0.0265 - val_auc: 0.6252 - val_prc: 0.2070\n",
      "Epoch 28/100\n",
      "6/8 [=====================>........] - ETA: 0s - loss: 0.3302 - tp: 67.0000 - fp: 28.0000 - tn: 10646.0000 - fn: 1547.0000 - accuracy: 0.8718 - precision: 0.7053 - recall: 0.0415 - auc: 0.7749 - prc: 0.3729Restoring model weights from the end of the best epoch: 18.\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3287 - tp: 90.0000 - fp: 41.0000 - tn: 13516.0000 - fn: 1958.0000 - accuracy: 0.8719 - precision: 0.6870 - recall: 0.0439 - auc: 0.7779 - prc: 0.3740 - val_loss: 0.4058 - val_tp: 11.0000 - val_fp: 34.0000 - val_tn: 2343.0000 - val_fn: 366.0000 - val_accuracy: 0.8548 - val_precision: 0.2444 - val_recall: 0.0292 - val_auc: 0.6300 - val_prc: 0.2125\n",
      "Epoch 00028: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23504ece208>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1bd84a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_metrics(history):\n",
    "  metrics = ['loss', 'prc', 'precision', 'recall']\n",
    "  for n, metric in enumerate(metrics):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    plt.subplot(2,2,n+1)\n",
    "    plt.plot(history.epoch, history.history[metric], color=colors[0], label='Train')\n",
    "    plt.plot(history.epoch, history.history['val_'+metric],\n",
    "             color=colors[0], linestyle=\"--\", label='Val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)\n",
    "    if metric == 'loss':\n",
    "      plt.ylim([0, plt.ylim()[1]])\n",
    "    elif metric == 'auc':\n",
    "      plt.ylim([0.8,1])\n",
    "    else:\n",
    "      plt.ylim([0,1])\n",
    "\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7822eac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history, label, n):\n",
    "  # Use a log scale on y-axis to show the wide range of values.\n",
    "  plt.semilogy(history.epoch, history.history['loss'],\n",
    "               color=colors[n], label='Train ' + label)\n",
    "  plt.semilogy(history.epoch, history.history['val_loss'],\n",
    "               color=colors[n], label='Val ' + label,\n",
    "               linestyle=\"--\")\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f6128e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(labels, predictions, p=0.5):\n",
    "  cm = confusion_matrix(labels, predictions > p)\n",
    "  plt.figure(figsize=(5,5))\n",
    "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "  plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "  plt.ylabel('Actual label')\n",
    "  plt.xlabel('Predicted label')\n",
    "\n",
    "  print('Legitimate Transactions Detected (True Negatives): ', cm[0][0])\n",
    "  print('Legitimate Transactions Incorrectly Detected (False Positives): ', cm[0][1])\n",
    "  print('Fraudulent Transactions Missed (False Negatives): ', cm[1][0])\n",
    "  print('Fraudulent Transactions Detected (True Positives): ', cm[1][1])\n",
    "  print('Total Fraudulent Transactions: ', np.sum(cm[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f4a8c3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(name, labels, predictions, **kwargs):\n",
    "  fp, tp, _ = sklearn.metrics.roc_curve(labels, predictions)\n",
    "\n",
    "  plt.plot(100*fp, 100*tp, label=name, linewidth=2, **kwargs)\n",
    "  plt.xlabel('False positives [%]')\n",
    "  plt.ylabel('True positives [%]')\n",
    "  plt.xlim([-0.5,20])\n",
    "  plt.ylim([80,100.5])\n",
    "  plt.grid(True)\n",
    "  ax = plt.gca()\n",
    "  ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0957ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(name, labels, predictions, **kwargs):\n",
    "  fp, tp, _ = sklearn.metrics.roc_curve(labels, predictions)\n",
    "\n",
    "  plt.plot(100*fp, 100*tp, label=name, linewidth=2, **kwargs)\n",
    "  plt.xlabel('False positives [%]')\n",
    "  plt.ylabel('True positives [%]')\n",
    "  plt.xlim([-0.5,20])\n",
    "  plt.ylim([80,100.5])\n",
    "  plt.grid(True)\n",
    "  ax = plt.gca()\n",
    "  ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "26504142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prc(name, labels, predictions, **kwargs):\n",
    "    precision, recall, _ = sklearn.metrics.precision_recall_curve(labels, predictions)\n",
    "\n",
    "    plt.plot(precision, recall, label=name, linewidth=2, **kwargs)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.grid(True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1a6007",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "577155bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val=pd.read_csv('../test_x.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ca995f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_pos_test=model.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "358dd4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val=pd.read_csv('../test_y.csv')\n",
    "y_val['target']=y_prob_pos_test\n",
    "y_val.to_csv('dnn.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee51822",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
